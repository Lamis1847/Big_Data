Objectif : Concevoir et optimiser un pipeline de traitement distribué pour les données massives visant à améliorer l’efficacité computationnelle et la gestion des ressources mémoire et CPU grâce à Apache Beam.

Réalisation :

Développement d’un pipeline de traitement de données massives avec Apache Beam, assurant un traitement scalable et performant.

Optimisation de l’utilisation mémoire en intégrant une lecture par morceaux (chunks) et une gestion dynamique des ressources.

Proposition et implémentation de stratégies d’optimisation pour éviter l’overflow mémoire, notamment par le partitionnement intelligent des données et l’ajustement des tailles de buffer
